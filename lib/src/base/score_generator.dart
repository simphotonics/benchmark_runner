import '../extension/benchmark_helper.dart';
import '../util/stats.dart';
import 'sample_size.dart';
import 'score.dart';

/// A synchronous function that does nothing.
void doNothing() {}

/// A class used to benchmark synchronous functions.
/// The benchmarked function is provided as a constructor argument.
class ScoreGenerator {
  /// Constructs a [ScoreGenerator] object using the following arguments:
  /// * [description]: a [String] describing the benchmark,
  /// * [run]: the synchronous function to be benchmarked,
  /// * [setup]: a function that is executed once before running the benchmark,
  /// * [teardown]: a function that is executed once after the benchmark has
  /// completed.
  const ScoreGenerator({
    required this.run,
    this.setup = doNothing,
    this.teardown = doNothing,
  });

  // The benchmarked function.
  final void Function() run;

  /// Setup function executed prior to the benchmark runs before [warmUp].
  final void Function() setup;

  /// Teardown function executed after the benchmark runs.
  final void Function() teardown;

  /// Generates a sample of benchmark scores.
  /// * The benchmark score entries represent the run time in microseconds.
  /// * The integer `innerIter` is larger than 1
  ///  if each score entry was averaged over
  /// `innerIter` runs.
  ({List<double> scores, int innerIterations}) sample({
    final Duration warmUpDuration = const Duration(milliseconds: 200),
    SampleSize? sampleSize,
  }) {
    setup();
    final sample = <int>[];

    final watch = Stopwatch();
    watch.prime();
    try {
      final scoreEstimate = watch.estimate(run, duration: warmUpDuration);
      sampleSize ??= BenchmarkHelper.sampleSize(scoreEstimate.elapsedTicks);
      if (sampleSize.innerIterations > 1) {
        final runs = sampleSize.innerIterations;
        for (var i = 0; i < sampleSize.length; i++) {
          // Averaging each score over sampleSize.innerIteration runs.
          // For details see function BenchmarkHelper.sampleSize.
          final score = watch.measure(run, runs);
          sample.add(score);
        }
      } else {
        for (var i = 0; i < sampleSize.length; i++) {
          watch.reset();
          watch.start();
          run();
          // These scores are not averaged.
          sample.add(watch.elapsedTicks);
        }
      }

      // Rescale to microseconds.
      // Note: frequency is expressed in Hz (ticks/second).
      return (
        scores:
            sample
                .map<double>(
                  (e) => e * (Duration.microsecondsPerSecond / watch.frequency),
                )
                .toList(),
        innerIterations: sampleSize.innerIterations,
      );
    } finally {
      teardown();
    }
  }

  /// Returns a [Score] object holding the total benchmark duration
  /// a [Stats] object created from the score sample, and a [Stats] object
  /// containg the inner loop counters (over how many runs each score sample
  /// is averaged over).
  /// * The run time entries represent durations in microseconds.
  /// * A score estimate is generated by running the benchmarked function
  /// for [warmUpDuration].
  /// * Before the measurement the function is exercised repeatedly at least
  /// [warmUpRuns] times.
  Score score({
    final Duration warmUpDuration = const Duration(microseconds: 200),
    SampleSize? sampleSize,
  }) {
    final watch = Stopwatch()..start();
    final sample = this.sample(
      warmUpDuration: warmUpDuration,
      sampleSize: sampleSize,
    );
    return Score(
      duration: watch.elapsed,
      scoreSample: sample.scores,
      innerIterations: sample.innerIterations,
    );
  }
}
